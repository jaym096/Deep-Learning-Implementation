{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-sQMW2R9j69w"
   },
   "source": [
    "# **Problem 1: Speaker Verification**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RB_lMElXESg9"
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import librosa\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import itertools\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import datasets, transforms\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision.datasets import MNIST\n",
    "import torch.utils.data as utils\n",
    "from torch.utils.data import TensorDataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p9-jBk_scPDO"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3MH6PSD-Ej2n",
    "outputId": "074dd22b-d9b3-485e-f640-e307fe146014"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500, 16180) (200, 22631)\n"
     ]
    }
   ],
   "source": [
    "train_files = pickle.load(open('/content/drive/MyDrive/Colab Notebooks/HW4/hw4_trs.pkl', 'rb'))\n",
    "test_files = pickle.load(open('/content/drive/MyDrive/Colab Notebooks/HW4/hw4_tes.pkl', 'rb'))\n",
    "\n",
    "# print shape\n",
    "print(train_files.shape, test_files.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EMIufeAAXa4J",
    "outputId": "835ddd5b-3d62-44b5-be78-36a4e794b13c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500, 32, 513)\n"
     ]
    }
   ],
   "source": [
    "# converting train data into stft\n",
    "train_stft = []\n",
    "for i in range(len(train_files)):\n",
    "    converted = np.abs(librosa.stft(train_files[i], n_fft=1024, hop_length=512).T)\n",
    "    train_stft.append(converted)\n",
    "\n",
    "# print shape\n",
    "train_stft = np.array(train_stft)\n",
    "print(train_stft.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pTYhJgeRYSXy",
    "outputId": "4f49a99a-8151-49b8-c536-09bf8a367b79"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200, 45, 513)\n"
     ]
    }
   ],
   "source": [
    "# converting test data into stft\n",
    "test_stft = []\n",
    "for i in range(len(test_files)):\n",
    "    converted = np.abs(librosa.stft(test_files[i], n_fft=1024, hop_length=512).T)\n",
    "    test_stft.append(converted)\n",
    "\n",
    "# print shape\n",
    "test_stft = np.array(test_stft)\n",
    "print(test_stft.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oAGMKuB3E4Kt",
    "outputId": "51c737a0-ccc8-49a2-d2da-875d34df37eb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50 (10, 32, 513)\n",
      "20 (10, 45, 513)\n"
     ]
    }
   ],
   "source": [
    "# spliting train and test based on the utterances of 50 people (20 for test)\n",
    "split_train = np.split(train_stft, 50)\n",
    "split_test = np.split(test_stft, 20)\n",
    "\n",
    "# print shape\n",
    "print(len(split_train), split_train[0].shape)\n",
    "print(len(split_test), split_test[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KY3erysvbBbA",
    "outputId": "46084a31-0510-42ab-9267-2dde0f80957a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of positive-negative examples\n",
      "50 50\n",
      "(45, 2, 32, 513) (45, 2, 32, 513)\n",
      "\n",
      "shape of train_list\n",
      "(4500, 2, 32, 513)\n"
     ]
    }
   ],
   "source": [
    "# training data\n",
    "positive_examples = []\n",
    "negative_examples = []\n",
    "for i in range(len(split_train)):\n",
    "    # getting utterance of an individual speaker\n",
    "    single_speaker = split_train[i]\n",
    "\n",
    "    # getting combinations of utterance for the individual speaker\n",
    "    positive = list(itertools.combinations(single_speaker, 2))\n",
    "    L = len(positive)\n",
    "    positive = np.array(positive)\n",
    "    positive_examples.append(positive)\n",
    "\n",
    "    utter490 = np.concatenate((train_stft[0:10 * i], train_stft[(10 + i*10):]))\n",
    "    utt1 = utter490[np.random.choice(utter490.shape[0], L, replace=True)]\n",
    "    utt2 = single_speaker[np.random.choice(single_speaker.shape[0], L, replace=True)]\n",
    "    # print(utt1.shape, utt2.shape)\n",
    "    \n",
    "    temp = []\n",
    "    for j in range(len(utt1)):\n",
    "        setter = (utt1[j], utt2[j])\n",
    "        temp.append(setter)\n",
    "    temp = np.array(temp)\n",
    "    negative_examples.append(temp)\n",
    "\n",
    "# print length\n",
    "print(\"shape of positive-negative examples\")\n",
    "print(len(positive_examples), len(negative_examples))\n",
    "print(positive_examples[0].shape, negative_examples[0].shape)\n",
    "\n",
    "train_list = []\n",
    "for i in range(len(positive_examples)):\n",
    "    temp = np.concatenate((positive_examples[i], negative_examples[i]), axis=0)\n",
    "    for j in range(len(temp)):\n",
    "        train_list.append(temp[j])\n",
    "\n",
    "print(\"\\nshape of train_list\")\n",
    "train_list = np.array(train_list)\n",
    "print(train_list.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4GSDBNALoTHM",
    "outputId": "5b34de46-a4d2-4829-ccc1-63f75bf7f662"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of positive-negative examples\n",
      "20 20\n",
      "(45, 2, 45, 513) (45, 2, 45, 513)\n",
      "\n",
      "shape of test_list\n",
      "(1800, 2, 45, 513)\n"
     ]
    }
   ],
   "source": [
    "# testing data\n",
    "positive_test = []\n",
    "negative_test = []\n",
    "for i in range(len(split_test)):\n",
    "    # getting utterance of an individual speaker\n",
    "    single_speaker = split_test[i]\n",
    "\n",
    "    # getting combinations of utterance for the individual speaker\n",
    "    positive = list(itertools.combinations(single_speaker, 2))\n",
    "    L = len(positive)\n",
    "    positive = np.array(positive)\n",
    "    positive_test.append(positive)\n",
    "\n",
    "    utter180 = np.concatenate((test_stft[0:10 * i], test_stft[(10 + i*10):]))\n",
    "    utt1 = utter180[np.random.choice(utter180.shape[0], L, replace=True)]\n",
    "    utt2 = single_speaker[np.random.choice(single_speaker.shape[0], L, replace=True)]\n",
    "    # print(utt1.shape, utt2.shape)\n",
    "    \n",
    "    temp = []\n",
    "    for j in range(len(utt1)):\n",
    "        setter = (utt1[j], utt2[j])\n",
    "        temp.append(setter)\n",
    "    temp = np.array(temp)\n",
    "    negative_test.append(temp)\n",
    "\n",
    "# print length\n",
    "print(\"shape of positive-negative examples\")\n",
    "print(len(positive_test), len(negative_test))\n",
    "print(positive_test[0].shape, negative_test[0].shape)\n",
    "\n",
    "test_list = []\n",
    "for i in range(len(positive_test)):\n",
    "    temp = np.concatenate((positive_test[i], negative_test[i]), axis=0)\n",
    "    for j in range(len(temp)):\n",
    "        test_list.append(temp[j])\n",
    "\n",
    "print(\"\\nshape of test_list\")\n",
    "test_list = np.array(test_list)\n",
    "print(test_list.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JtGBwf510ep5",
    "outputId": "2d9cd8d9-ad27-4ad1-c081-da8146d65fcc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([90])\n",
      "torch.Size([4500])\n",
      "torch.Size([1800])\n"
     ]
    }
   ],
   "source": [
    "pos_labels = torch.ones((L))\n",
    "neg_labels = torch.zeros((L))\n",
    "labs = torch.cat([pos_labels, neg_labels], dim=0)\n",
    "print(labs.shape)\n",
    "\n",
    "# train labels\n",
    "train_labels = torch.Tensor([])\n",
    "for i in range(len(positive_examples)):\n",
    "    train_labels = torch.cat([train_labels, labs], dim=0)\n",
    "print(train_labels.shape)\n",
    "\n",
    "# test labels\n",
    "test_labels = torch.Tensor([])\n",
    "for i in range(len(positive_test)):\n",
    "    test_labels = torch.cat([test_labels, labs], dim=0)\n",
    "print(test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nUFOIFypE1-j",
    "outputId": "d1889106-13bf-489f-f87b-a1bfdab6aed5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150\n",
      "torch.Size([30, 2, 32, 513]) torch.Size([30])\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# create a data loader for train data\n",
    "trainSet = utils.TensorDataset(torch.Tensor(train_list).to(device), torch.Tensor(train_labels).to(device))\n",
    "train_loader = utils.DataLoader(trainSet, batch_size=30, shuffle=True)\n",
    "\n",
    "print(len(train_loader))\n",
    "a, b = next(iter(train_loader))\n",
    "print(a.shape, b.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uEdgTQzZblGD",
    "outputId": "ed8dd150-8ca8-4aed-dcda-0d7c51f3ce90"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90\n",
      "torch.Size([20, 2, 45, 513]) torch.Size([20])\n"
     ]
    }
   ],
   "source": [
    "# create a data loader for test data\n",
    "testSet = utils.TensorDataset(torch.Tensor(test_list).to(device), test_labels.to(device))\n",
    "test_loader = utils.DataLoader(testSet, batch_size=20, shuffle=True)\n",
    "\n",
    "print(len(test_loader))\n",
    "a, b = next(iter(test_loader))\n",
    "print(a.shape, b.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6HEuMuwIb5op",
    "outputId": "8578a0e9-e977-449c-ed62-198574d9a723"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SiameseNet(\n",
      "  (lstm): LSTM(513, 513, num_layers=2, batch_first=True)\n",
      "  (fc1): Linear(in_features=513, out_features=256, bias=True)\n",
      "  (fc3): Linear(in_features=256, out_features=50, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class SiameseNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SiameseNet, self).__init__()\n",
    "        self.lstm  = nn.LSTM(input_size=513, hidden_size=513, num_layers=2, batch_first=True)\n",
    "        self.fc1 = nn.Linear(in_features=513, out_features=256)\n",
    "        self.fc2 = nn.Linear(in_features=256, out_features=128)\n",
    "        self.fc3 = nn.Linear(in_features=256, out_features=50)\n",
    "\n",
    "\n",
    "    def forward_once(self, x):\n",
    "          # Forward pass \n",
    "        x, _ = self.lstm(x)\n",
    "        x = x[:, -1, :]\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "    def forward(self, ip1, ip2):\n",
    "        # passing input 1 into the network\n",
    "        out1 = self.forward_once(ip1)\n",
    "        # passing input 2 into the network\n",
    "        out2 = self.forward_once(ip2)\n",
    "        return out1, out2\n",
    "\n",
    "net = SiameseNet()\n",
    "net.to(device)\n",
    "err_func = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=3e-5)\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MQYgNCq_eeLA"
   },
   "source": [
    "In the previous assignment we used LSTMs to denoise the audios, Since the results were really good, I decided to go with the LSTM for this assignment as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "K2Ne2A_Debw8",
    "outputId": "ddfda59c-331f-46df-f959-2b357a7244ea"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH:5   |   train_loss:0.5504   |   acc:74.267    |   correct:3342\n",
      "EPOCH:10   |   train_loss:0.5068   |   acc:77.556    |   correct:3490\n",
      "EPOCH:15   |   train_loss:0.4721   |   acc:80.467    |   correct:3621\n",
      "EPOCH:20   |   train_loss:0.4227   |   acc:82.111    |   correct:3695\n",
      "EPOCH:25   |   train_loss:0.3794   |   acc:83.889    |   correct:3775\n",
      "EPOCH:30   |   train_loss:0.3251   |   acc:86.644    |   correct:3899\n",
      "EPOCH:35   |   train_loss:0.2937   |   acc:88.111    |   correct:3965\n",
      "EPOCH:40   |   train_loss:0.2405   |   acc:90.111    |   correct:4055\n",
      "EPOCH:45   |   train_loss:0.2042   |   acc:91.467    |   correct:4116\n",
      "EPOCH:50   |   train_loss:0.1749   |   acc:93.133    |   correct:4191\n",
      "EPOCH:55   |   train_loss:0.1382   |   acc:94.578    |   correct:4256\n",
      "EPOCH:60   |   train_loss:0.1146   |   acc:95.422    |   correct:4294\n",
      "EPOCH:65   |   train_loss:0.0916   |   acc:96.244    |   correct:4331\n",
      "EPOCH:70   |   train_loss:0.0637   |   acc:97.489    |   correct:4387\n",
      "EPOCH:75   |   train_loss:0.0666   |   acc:97.444    |   correct:4385\n",
      "EPOCH:80   |   train_loss:0.0527   |   acc:98.244    |   correct:4421\n",
      "EPOCH:85   |   train_loss:0.0356   |   acc:98.756    |   correct:4444\n",
      "EPOCH:90   |   train_loss:0.0595   |   acc:97.778    |   correct:4400\n",
      "EPOCH:95   |   train_loss:0.0237   |   acc:99.244    |   correct:4466\n",
      "EPOCH:100   |   train_loss:0.0345   |   acc:98.667    |   correct:4440\n"
     ]
    }
   ],
   "source": [
    "epochs = 100\n",
    "accuracy_list = []\n",
    "for e in range(1, epochs + 1):\n",
    "    train_loss = 0\n",
    "    correct = 0\n",
    "    for data, target in train_loader:\n",
    "        ip1 = data[:, 0]\n",
    "        ip2 = data[:, 1]\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        out1, out2 = net(ip1, ip2)\n",
    "        out1 = out1.reshape(out1.shape[0], 1, -1)\n",
    "        out2 = out2.reshape(out2.shape[0], 1, -1)\n",
    "        result = torch.flatten(torch.bmm(out1, out2.permute(0, 2, 1)))\n",
    "\n",
    "        temp_list = []\n",
    "        for r in result:\n",
    "            if torch.sigmoid(r) >= 0.5:\n",
    "                temp_list.append(1)\n",
    "            else:\n",
    "                temp_list.append(0)\n",
    "\n",
    "        temp_list = torch.Tensor(temp_list).to(device)\n",
    "        correct += (temp_list == target).sum().item()\n",
    "\n",
    "        loss = err_func(result, target)\n",
    "        train_loss += loss.item()\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    acc = correct/len(train_loader.dataset) * 100\n",
    "    accuracy_list.append(acc)\n",
    "    if e%5 == 0:\n",
    "        print(\"EPOCH:{eps}   |   train_loss:{tls}   |   acc:{accu}    |   correct:{corr}\".\n",
    "              format(eps = e, tls=round(train_loss/len(train_loader),4), accu=round(acc,3), corr=correct))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "72NIWQdqW_pn",
    "outputId": "a6951eb9-ecc1-4b68-bc64-72b04db1733e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 69.667\n"
     ]
    }
   ],
   "source": [
    "# running_loss = 0\n",
    "correct = 0\n",
    "with torch.no_grad():\n",
    "    net.eval()\n",
    "    for data, target in test_loader:\n",
    "        ip1 = data[:, 0]\n",
    "        ip2 = data[:, 1]\n",
    "\n",
    "        out1, out2 = net(ip1, ip2)\n",
    "        out1 = out1.reshape(out1.shape[0], 1, -1)\n",
    "        out2 = out2.reshape(out2.shape[0], 1, -1)\n",
    "        result = torch.flatten(torch.bmm(out1, out2.permute(0, 2, 1)))\n",
    "\n",
    "        temp_list = []\n",
    "        for each in result:\n",
    "            if torch.sigmoid(each) > 0.5:\n",
    "                temp_list.append(1)\n",
    "            else:\n",
    "                temp_list.append(0)\n",
    "\n",
    "        temp_list = torch.Tensor(temp_list).to(device)\n",
    "        correct += (temp_list == target).sum().item()\n",
    "\n",
    "print(\"Test Accuracy: {acc}\".format(acc= round((correct / len(test_loader.dataset))*100, 3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mJziqs18HayF"
   },
   "source": [
    "After trying out various archtecture, tuning various hyperparameters, this was the best results I got. No matter what, my accuracy did not go above 70. "
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "HW4_1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
